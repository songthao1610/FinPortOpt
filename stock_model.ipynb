{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2015 - March 2024 -> test: march - june 2024\n",
    "try models: arima + lstm + xgboost + tiny time mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pmdarima import auto_arima\n",
    "import torch\n",
    "from keras.api.models import Sequential\n",
    "from keras.api.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'AAPL'\n",
    "data_train = yf.download(ticker, start='2015-01-01', end='2024-03-01')\n",
    "data_test = yf.download(ticker, start='2024-03-01', end='2024-06-30')\n",
    "full_data = pd.concat([data_train, data_test]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train.to_csv(rf'C:\\Users\\MY PC\\Project\\data\\{ticker}_stock_train.csv')\n",
    "# data_test.to_csv(rf'C:\\Users\\MY PC\\Project\\data\\{ticker}_stock_test.csv')\n",
    "# full_data.to_csv(rf'C:\\Users\\MY PC\\Project\\data\\{ticker}_stock.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Determine that this is univariate time series forecasting\n",
    "- Good models: ARIMA, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OHLCV graph with plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=go.Ohlc(x=full_data['Date'],\n",
    "                    open=full_data['Open'],\n",
    "                    high=full_data['High'],\n",
    "                    low=full_data['Low'],\n",
    "                    close=full_data['Close']),\n",
    "\t\t\t\t\tlayout=go.Layout(title=f'{ticker} Stock Price from January 2015 to June 2024',))\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=1100,\n",
    "    height=700,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_arima_forecasts(df, cat_col, formatted_date, target_col,\n",
    "#                         start_date, end_date, context_len=64):\n",
    "#     \"\"\"\n",
    "#     Forecast stock value with ARIMA\n",
    "\n",
    "#     Parameters:\n",
    "#     df (pd.DataFrame): The input DataFrame.\n",
    "#     cat_col (str): The column name for categories.\n",
    "#     formatted_date (str): Date column name.\n",
    "#     target_col (str): The target variable to correlate with other variables.\n",
    "#     start_date (str): Lower bound for normal data\n",
    "#     end_date (str): Upper bound for normal data. Normal data is used as training\n",
    "#     resource for ARIMA model\n",
    "#     context_len (int, Default=64): number of points to make prediction on\n",
    "\n",
    "#     Returns: a dictionary containing 'train_data','test_data',\n",
    "#     'forecasts', 'actuals', 'timestamps' (date) and 'forecast_timestamps'\n",
    "\n",
    "#     \"\"\"\n",
    "\n",
    "#     def get_arma_forecast(context, p=1, r=0, q=0):\n",
    "#         arma = ARIMA(context, order=(p, r, q)).fit(\n",
    "#             method_kwargs={\"warn_convergence\": False}\n",
    "#         )\n",
    "#         predict_cat = arma.predict(len(context), len(context))\n",
    "#         return predict_cat\n",
    "\n",
    "#     df[formatted_date] = pd.to_datetime(df[formatted_date])\n",
    "#     cats = list(df[cat_col].unique())\n",
    "\n",
    "#     predictions = {}\n",
    "\n",
    "#     # Extract normal data\n",
    "#     normal_data = df[\n",
    "#         (df[formatted_date] >= start_date) & (df[formatted_date] <= end_date)\n",
    "#     ]\n",
    "\n",
    "#     for x in cats:\n",
    "#         sep_df = df[df[cat_col] == x]\n",
    "\n",
    "#         # Prepare data for scaling\n",
    "#         train_data = normal_data[normal_data[cat_col] == x][[target_col]].values\n",
    "\n",
    "#         # Scale the data using the same scaler for training and test data\n",
    "#         scaler = StandardScaler()\n",
    "#         scaled_train_data = scaler.fit_transform(train_data)\n",
    "\n",
    "#         # Prepare test data\n",
    "#         test_data = df[(df[formatted_date] > end_date) & (df[cat_col] == x)][\n",
    "#             [target_col]\n",
    "#         ].values\n",
    "#         scaled_test_data = scaler.transform(test_data)\n",
    "\n",
    "#         forecast_len = 1  # Predicting the next value\n",
    "\n",
    "#         arma_summary = []\n",
    "\n",
    "#         for idx in range(len(scaled_test_data) - context_len - forecast_len + 1):\n",
    "#             context = scaled_test_data[idx : idx + context_len]\n",
    "#             actual = scaled_test_data[\n",
    "#                 idx + context_len : idx + context_len + forecast_len\n",
    "#             ]\n",
    "#             forecast = get_arma_forecast(context)\n",
    "#             arma_summary.append((context, actual, forecast))\n",
    "\n",
    "#         # Extract actual and forecast values\n",
    "#         arma_actual = [i[1][0] for i in arma_summary]\n",
    "#         arma_forecast = [i[2][0] for i in arma_summary]\n",
    "\n",
    "#         # Inverse transform the scaled data for evaluation\n",
    "#         inv_train_data = scaler.inverse_transform(scaled_train_data)\n",
    "#         inv_test_data = scaler.inverse_transform(scaled_test_data)\n",
    "#         inv_arma_forecast = scaler.inverse_transform(\n",
    "#             np.array(arma_forecast).reshape(-1, 1)\n",
    "#         )\n",
    "\n",
    "#         predictions[x] = {\n",
    "#             \"train_data\": inv_train_data,\n",
    "#             \"test_data\": inv_test_data,\n",
    "#             \"forecasts\": inv_arma_forecast,\n",
    "#             \"actuals\": arma_actual,\n",
    "#             \"timestamps\": sep_df[formatted_date],\n",
    "#             \"forecast_timestamps\": sep_df[formatted_date][\n",
    "#                 len(train_data)\n",
    "#                 + context_len : len(train_data)\n",
    "#                 + context_len\n",
    "#                 + len(arma_forecast)\n",
    "#             ],\n",
    "#             cat_col: x,\n",
    "#         }\n",
    "\n",
    "#         # Calculate and print MSE\n",
    "#         if len(arma_actual) > 0 and len(arma_forecast) > 0:\n",
    "#             actual_array = np.array(arma_actual)\n",
    "#             forecast_array = np.array(arma_forecast)\n",
    "#             mape = np.mean(np.abs(actual_array - forecast_array / actual_array))\n",
    "#             print(f\"MSE for {x}: {np.round(mse(arma_actual, arma_forecast), 5)}\")\n",
    "#             print(f\"MAD for {x}: {sm.robust.scale.mad(arma_forecast)}\")\n",
    "#             print(f\"MAPE for {x}: {mape * 100:.2f}%\")\n",
    "#         else:\n",
    "#             raise ValueError(\n",
    "#                 \"No forecasts were generated. Check your data and sliding window configuration.\"\n",
    "#             )\n",
    "\n",
    "#     return pd.DataFrame(predictions)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
